{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vorbis Audio Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "1. Overlaped subband analysis using [MDCT](http://en.wikipedia.org/wiki/Modified_discrete_cosine_transform).\n",
    "2. Perceptual quantization.\n",
    "3. Entropy coding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlaped processing\n",
    "\n",
    "```\n",
    "0              N-1            2N-1            3N-1\n",
    "+---------------+---------------+---------------+ s[n]\n",
    "<--------Transform Step--------->\n",
    "                <---------Transform Step-------->\n",
    "```\n",
    "\n",
    "* Each transform step inputs $2N$ samples and outputs $N$ MDCT coeficients.\n",
    "\n",
    "* $N$ can vary depending on the characteristics of the sound. For\n",
    "  \\emph{complex} sounds without clear armonics (such as a plosive sound),\n",
    "  shortened windows improve the performance. For \\emph{simple} sounds\n",
    "  (such as a music instrument), large windows are better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channel coupling\n",
    "\n",
    "Most of the time, similar sounds are transported in the channels\n",
    "  of a non-mono audio signal. Channel coupling decreases inter-channel\n",
    "  redundancy, usually, using prediction techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptual quantization\n",
    "\n",
    "Depending on the desired output bit-rate and the frequency (see\n",
    "  the ATH model), the SAM applies a different quantization step to\n",
    "  barks (see Section~\\ref{sec:ATH}). Roughly speaking, the higher the\n",
    "  compression ratio, the larger the quantization step and therefore,\n",
    "  the quantization noise; and the higher the frequency, the wider the\n",
    "  bark. Notice also that the perception of a tone in a bark depends\n",
    "  also on the temporal masking.\n",
    "  \n",
    "At decoding time, those barks that suffered the biggest lossess\n",
    "  are usually filled with\n",
    "  \\href{http://en.wikipedia.org/wiki/White_noise}{white noise} in\n",
    "  order to \\href{http://simplynoise.com/}{increase the perceived\n",
    "    quality}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDCT (Modified Discrete Cosine Transform)\n",
    "\n",
    "* Equivalent to apply a\n",
    "  \\href{http://en.wikipedia.org/wiki/Filter_bank}{bank} of $N$\n",
    "  filters.\n",
    "  \n",
    "* Determines the correlation between a set of $2N$ numbers\n",
    "  (samples) and $N$\n",
    "  \\href{http://en.wikipedia.org/wiki/Orthogonality}{orthogonal}\\footnote{Two\n",
    "    functions/signals are orthogonal if it is impossible to obtain one\n",
    "    of them by means of the other.} \\href{http://guru.multimedia.cx/mdct/}{cosine functions}. Therefore,\n",
    "  at the input of the DCT there are $2N$ samples and at the output,\n",
    "  $N$ coefficients.\n",
    "    \n",
    "* The MDCT coefficients $S[w]$ of the PCM samples $s[n]$ are\n",
    "  defined as:\n",
    "  \\begin{equation}\n",
    "    S[w] = \\sum_{n=0}^{2N-1}s[n]cos\\Big[\\frac{\\pi}{N}(n+\\frac{1}{2}+\\frac{N}{2})(w+\\frac{1}{2})\\B\n",
    "ig].\n",
    "    \\label{eq:MDCT}\n",
    "  \\end{equation}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
